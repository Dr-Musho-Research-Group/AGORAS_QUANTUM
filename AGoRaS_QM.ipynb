{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWHCr-6PCvlV",
        "outputId": "8737e61f-ba46-4f47-bb21-db0e14c20398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.17.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 32.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.17.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n",
            "\u001b[K     |████████████████████████████████| 256 kB 27.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.12\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons\n",
        "# !pip install keras\n",
        "!pip3 install pickle5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAaQJVFVCOfZ"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional, Dense, Embedding, Input, Lambda, LSTM, RepeatVector, TimeDistributed, Layer, Activation, Dropout\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers.advanced_activations import ELU\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "# from scipy import spatial\n",
        "import tensorflow as tf\n",
        "# import pandas as pd\n",
        "import numpy as np\n",
        "# import codecs\n",
        "import pickle5 as pk\n",
        "import os\n",
        "from pathlib import Path\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGJSBpoc96XX",
        "outputId": "92dd20d3-6d66-47cb-fdb7-777994f3c332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxWa_eKKCdEI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.framework.ops import disable_eager_execution \n",
        "disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3AZVz_xCOfn"
      },
      "outputs": [],
      "source": [
        "path_to_training_data = Path.cwd().joinpath(\"quantum_material_data.pkl\")\n",
        "with open(path_to_training_data, 'rb') as f:\n",
        "    data = pk.load(f)\n",
        "\n",
        "\n",
        "dataset = data[\"training_data\"]\n",
        "tokenizer = data[\"tokenizer\"]\n",
        "\n",
        "\n",
        "number_of_equations = dataset.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paJBk8I4COfq",
        "outputId": "bfbd0935-a110-4c4a-f768-ea1752c0fba4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8464, 200)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxO_MhSICOfs",
        "outputId": "d4654113-7790-44a4-d4f6-1a17935e4bba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8464"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "number_of_equations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwEvWQveCOfu"
      },
      "outputs": [],
      "source": [
        "np.random.shuffle(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1MYQ8BoCOfw",
        "outputId": "a1d18c97-d838-46ef-ff08-64c65c5bd606"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2,  2,  6, ...,  0,  0,  0],\n",
              "       [ 6,  2,  2, ...,  0,  0,  0],\n",
              "       [25, 27,  1, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [30, 11, 30, ...,  0,  0,  0],\n",
              "       [ 2,  4,  8, ...,  0,  0,  0],\n",
              "       [ 1,  3,  1, ...,  0,  0,  0]], dtype=int32)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1DljDELCOfx"
      },
      "outputs": [],
      "source": [
        "training = dataset[:7400].astype(np.int32)\n",
        "test = dataset[7400:8400].astype(np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXZsyAgxCOf0"
      },
      "outputs": [],
      "source": [
        "#used to be 25\n",
        "batch_size = 25\n",
        "epochs = 100\n",
        "max_len = len(dataset[1])\n",
        "latent_dim = 100\n",
        "intermediate_dim = 50\n",
        "emb_dim = 100\n",
        "epsilon_std = 1.0\n",
        "kl_weight = 0.1\n",
        "number_of_letters = len(tokenizer.word_index) + 1\n",
        "learning_rate = 1e-5\n",
        "num_sampled=500\n",
        "act = ELU()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oigDaPsICOf2",
        "outputId": "3770833f-06f4-4f24-e1b0-62a58b6953d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "x = Input(batch_shape=(None, max_len))\n",
        "x_embed = Embedding(max_len, emb_dim,\n",
        "                            input_length=max_len, trainable=False)(x)\n",
        "h = Bidirectional(LSTM(intermediate_dim, return_sequences=False, recurrent_dropout=0.5), merge_mode='concat')(x_embed)\n",
        "#h = Bidirectional(LSTM(intermediate_dim, return_sequences=False), merge_mode='concat')(h)\n",
        "h = Dropout(0.5)(h)\n",
        "h = Dense(intermediate_dim, activation='linear')(h)\n",
        "h = act(h)\n",
        "h = Dropout(0.5)(h)\n",
        "z_mean = Dense(latent_dim)(h)\n",
        "z_log_var = Dense(latent_dim)(h)\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n",
        "                              stddev=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
        "\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "\n",
        "# we instantiate these layers separately so as to reuse them later\n",
        "repeated_context = RepeatVector(max_len)\n",
        "decoder_h = LSTM(intermediate_dim, return_sequences=True, recurrent_dropout=0.5)\n",
        "decoder_mean = TimeDistributed(Dense(number_of_letters, activation='linear'))#softmax is applied in the seq2seqloss by tf\n",
        "h_decoded = decoder_h(repeated_context(z))\n",
        "x_decoded_mean = decoder_mean(h_decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Urh0hktDCOf5"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# placeholder loss\n",
        "def zero_loss(y_true, y_pred):\n",
        "    return K.zeros_like(y_pred)\n",
        "\n",
        "# #=========================== Necessary only if you want to use Sampled Softmax =======================#\n",
        "# #Sampled softmax\n",
        "# logits = tf.constant(np.random.randn(batch_size, max_len, NB_WORDS), tf.float32)\n",
        "# targets = tf.constant(np.random.randint(NB_WORDS, size=(batch_size, max_len)), tf.int32)\n",
        "# proj_w = tf.constant(np.random.randn(NB_WORDS, NB_WORDS), tf.float32)\n",
        "# proj_b = tf.constant(np.zeros(NB_WORDS), tf.float32)\n",
        "\n",
        "# def _sampled_loss(labels, logits):\n",
        "#     labels = tf.cast(labels, tf.int64)\n",
        "#     labels = tf.reshape(labels, [-1, 1])\n",
        "#     logits = tf.cast(logits, tf.float32)\n",
        "#     return tf.cast(\n",
        "#                     tf.nn.sampled_softmax_loss(\n",
        "#                         proj_w,\n",
        "#                         proj_b,\n",
        "#                         labels,\n",
        "#                         logits,\n",
        "#                         num_sampled=num_sampled,\n",
        "#                         num_classes=NB_WORDS),\n",
        "#                     tf.float32)\n",
        "# softmax_loss_f = _sampled_loss\n",
        "#====================================================================================================#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO85zkv3_o_E",
        "outputId": "ae90d099-10c6-4fcb-c8fd-2e3a6477d4b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(None, 200) (25, 200, 59)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 200, 100)     20000       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 100)          60400       ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 100)          0           ['bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 50)           5050        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " elu (ELU)                      (None, 50)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 50)           0           ['elu[0][0]']                    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 100)          5100        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 100)          5100        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (25, 100)            0           ['dense_1[0][0]',                \n",
            "                                                                  'dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVector)   (25, 200, 100)       0           ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (25, 200, 50)        30200       ['repeat_vector[0][0]']          \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (25, 200, 59)       3009        ['lstm_1[0][0]']                 \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            " custom_variational_layer (Cust  (None, 200)         0           ['input_1[0][0]',                \n",
            " omVariationalLayer)                                              'time_distributed[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 128,859\n",
            "Trainable params: 108,859\n",
            "Non-trainable params: 20,000\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Custom VAE loss layer\n",
        "class CustomVariationalLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.is_placeholder = True\n",
        "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
        "        self.target_weights = tf.constant(np.ones((batch_size, max_len)), tf.float32)\n",
        "\n",
        "    def vae_loss(self, x, x_decoded_mean):\n",
        "        #xent_loss = K.sum(metrics.categorical_crossentropy(x, x_decoded_mean), axis=-1)\n",
        "        labels = tf.cast(x, tf.int32)\n",
        "        xent_loss = K.sum(tfa.seq2seq.sequence_loss(x_decoded_mean, labels, \n",
        "                                                     weights=self.target_weights,\n",
        "                                                     average_across_timesteps=False,\n",
        "                                                     average_across_batch=False), axis=-1)\n",
        "                                                     #softmax_loss_function=softmax_loss_f), axis=-1)#, uncomment for sampled doftmax\n",
        "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "        return K.mean(xent_loss + kl_loss)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs[0]\n",
        "        x_decoded_mean = inputs[1]\n",
        "        print(x.shape, x_decoded_mean.shape)\n",
        "        loss = self.vae_loss(x, x_decoded_mean)\n",
        "        self.add_loss(loss, inputs=inputs)\n",
        "        # we don't use this output, but it has to have the correct shape:\n",
        "        return K.ones_like(x)\n",
        "\n",
        "loss_layer = CustomVariationalLayer()([x, x_decoded_mean])\n",
        "vae = Model(x, [loss_layer])\n",
        "opt = Adam(lr=0.01) #SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "vae.compile(optimizer='adam', loss=[zero_loss])\n",
        "vae.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4JGtlrZ_0pN",
        "outputId": "33dcacf3-e129-4261-97c2-b769f8cce0af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 7400 samples, validate on 1000 samples\n",
            "Epoch 1/100\n",
            "1375/7400 [====>.........................] - ETA: 5:08 - loss: 497.1759"
          ]
        }
      ],
      "source": [
        "def create_model_checkpoint(dir, model_name):\n",
        "    filepath = dir + '/' + model_name + \".h5\" #-{epoch:02d}-{decoded_mean:.2f}\n",
        "    directory = os.path.dirname(filepath)\n",
        "    try:\n",
        "        os.stat(directory)\n",
        "    except:\n",
        "        os.mkdir(directory)\n",
        "    checkpointer = ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=False)\n",
        "    return checkpointer\n",
        "\n",
        "checkpointer = create_model_checkpoint('models', 'vae_seq2seq')\n",
        "\n",
        "nb_epoch=100\n",
        "\n",
        "vae.fit(training, training,\n",
        "      epochs=epochs,\n",
        "      batch_size=batch_size,\n",
        "      validation_data=(test, test), callbacks=[checkpointer])\n",
        "# n_steps = (800000/2)/batch_size #we use the first 800000\n",
        "# for counter in range(nb_epoch):\n",
        "#     print('-------epoch: ',counter,'--------')\n",
        "#     vae.fit_generator(sent_generator(TRAIN_DATA_FILE, batch_size/2),\n",
        "#                           steps_per_epoch=n_steps, epochs=1, callbacks=[checkpointer],\n",
        "#                           validation_data=(data_1_val, data_1_val))\n",
        "    \n",
        "vae.save('models/vae_lstm800k32dim96hid.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbcZFTdUDm_z"
      },
      "outputs": [],
      "source": [
        "encoder = Model(x, z_mean)\n",
        "\n",
        "# build a generator that can sample sentences from the learned distribution\n",
        "decoder_input = Input(shape=(latent_dim,))\n",
        "_h_decoded = decoder_h(repeated_context(decoder_input))\n",
        "_x_decoded_mean = decoder_mean(_h_decoded)\n",
        "_x_decoded_mean = Activation('softmax')(_x_decoded_mean)\n",
        "generator = Model(decoder_input, _x_decoded_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfKw2JaZDqGB"
      },
      "outputs": [],
      "source": [
        "index2word = {v: k for k, v in word_index.items()}\n",
        "sent_encoded = encoder.predict(data_1_val, batch_size = 16)\n",
        "x_test_reconstructed = generator.predict(sent_encoded)\n",
        "                                         \n",
        "sent_idx = 672\n",
        "reconstructed_indexes = np.apply_along_axis(np.argmax, 1, x_test_reconstructed[sent_idx])\n",
        "#np.apply_along_axis(np.max, 1, x_test_reconstructed[sent_idx])\n",
        "#np.max(np.apply_along_axis(np.max, 1, x_test_reconstructed[sent_idx]))\n",
        "word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
        "word_list\n",
        "original_sent = list(np.vectorize(index2word.get)(data_1_val[sent_idx]))\n",
        "original_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeGJoCdqDvKR"
      },
      "outputs": [],
      "source": [
        "# function to parse a sentence\n",
        "def sent_parse(sentence, mat_shape):\n",
        "    sequence = tokenizer.texts_to_sequences(sentence)\n",
        "    padded_sent = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    return padded_sent#[padded_sent, sent_one_hot]\n",
        "\n",
        "# input: encoded sentence vector\n",
        "# output: encoded sentence vector in dataset with highest cosine similarity\n",
        "def find_similar_encoding(sent_vect):\n",
        "    all_cosine = []\n",
        "    for sent in sent_encoded:\n",
        "        result = 1 - spatial.distance.cosine(sent_vect, sent)\n",
        "        all_cosine.append(result)\n",
        "    data_array = np.array(all_cosine)\n",
        "    maximum = data_array.argsort()[-3:][::-1][1]\n",
        "    new_vec = sent_encoded[maximum]\n",
        "    return new_vec\n",
        "\n",
        "# input: two points, integer n\n",
        "# output: n equidistant points on the line between the input points (inclusive)\n",
        "def shortest_homology(point_one, point_two, num):\n",
        "    dist_vec = point_two - point_one\n",
        "    sample = np.linspace(0, 1, num, endpoint = True)\n",
        "    hom_sample = []\n",
        "    for s in sample:\n",
        "        hom_sample.append(point_one + s * dist_vec)\n",
        "    return hom_sample\n",
        "\n",
        "# input: original dimension sentence vector\n",
        "# output: sentence text\n",
        "def print_latent_sentence(sent_vect):\n",
        "    sent_vect = np.reshape(sent_vect,[1,latent_dim])\n",
        "    sent_reconstructed = generator.predict(sent_vect)\n",
        "    sent_reconstructed = np.reshape(sent_reconstructed,[max_len,NB_WORDS])\n",
        "    reconstructed_indexes = np.apply_along_axis(np.argmax, 1, sent_reconstructed)\n",
        "    np.apply_along_axis(np.max, 1, x_test_reconstructed[sent_idx])\n",
        "    np.max(np.apply_along_axis(np.max, 1, x_test_reconstructed[sent_idx]))\n",
        "    word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
        "    w_list = [w for w in word_list if w]\n",
        "    print(' '.join(w_list))\n",
        "    #print(word_list)\n",
        "        \n",
        "def new_sents_interp(sent1, sent2, n):\n",
        "    tok_sent1 = sent_parse(sent1, [15])\n",
        "    tok_sent2 = sent_parse(sent2, [15])\n",
        "    enc_sent1 = encoder.predict(tok_sent1, batch_size = 16)\n",
        "    enc_sent2 = encoder.predict(tok_sent2, batch_size = 16)\n",
        "    test_hom = shortest_homology(enc_sent1, enc_sent2, n)\n",
        "    for point in test_hom:\n",
        "        print_latent_sentence(point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6j84uCnD3O3"
      },
      "outputs": [],
      "source": [
        "sentence1=['where can i find a book on machine learning']\n",
        "mysent = sent_parse(sentence1, [15])\n",
        "mysent_encoded = encoder.predict(mysent, batch_size = 16)\n",
        "print_latent_sentence(mysent_encoded)\n",
        "print_latent_sentence(find_similar_encoding(mysent_encoded))\n",
        "\n",
        "sentence2=['how can i become a successful entrepreneur']\n",
        "mysent2 = sent_parse(sentence2, [15])\n",
        "mysent_encoded2 = encoder.predict(mysent2, batch_size = 16)\n",
        "print_latent_sentence(mysent_encoded2)\n",
        "print_latent_sentence(find_similar_encoding(mysent_encoded2))\n",
        "print('-----------------')\n",
        "\n",
        "new_sents_interp(sentence1, sentence2, 6)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of AGoRaS_QM_notebook.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "7044b324f88c4208d441c8fce3c8f6c454026eeaf7e810a2852062e3590255dc"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('tf': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
